# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ca8kDGCPShHF085Pe-QzUkP0bHCxnd8s
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras import layers, models
from keras.applications import ResNet50
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import RandomOverSampler
from sklearn.utils.class_weight import compute_class_weight
from sklearn.utils import class_weight
from keras.optimizers import Adam

IMAGE_HEIGHT = 128
IMAGE_WIDTH = 128
BATCH_SIZE = 32
NUM_CLASSES = 7
NUM_EPOCHS = 30

from google.colab import drive
drive.mount('/content/drive')
dataset_dir = '/content/drive/MyDrive/Main dataset'

def load_dataset(dataset_dir):
    images = []
    labels = []
    valid_extensions = ['.png', '.jpg', '.jpeg']
    label_encoder = LabelEncoder()

    for label in os.listdir(dataset_dir):
        label_path = os.path.join(dataset_dir, label)
        if os.path.isdir(label_path):
            for image_name in os.listdir(label_path):
                image_path = os.path.join(label_path, image_name)
                file_ext = os.path.splitext(image_path)[1].lower()
                if file_ext in valid_extensions:
                    try:
                        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))
                        image = tf.keras.preprocessing.image.img_to_array(image)
                        images.append(image)
                        labels.append(label)
                    except Exception as e:
                        print(f"Error loading image {image_path}: {e}")
                else:
                    print(f"Ignoring unsupported file format: {file_ext}")

    if not images:
        raise ValueError("No valid images found in the dataset directory.")

    labels = label_encoder.fit_transform(labels)
    labels = tf.keras.utils.to_categorical(labels, num_classes=NUM_CLASSES)

    return np.array(images), np.array(labels)

images, labels = load_dataset(dataset_dir)

train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)
train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)

train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = train_datagen.flow(train_images, train_labels, batch_size=BATCH_SIZE)
ros = RandomOverSampler(random_state=42)
train_images_resampled, train_labels_resampled = ros.fit_resample(train_images.reshape(-1, IMAGE_HEIGHT * IMAGE_WIDTH * 3), train_labels)
train_images_resampled = train_images_resampled.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)
train_labels_resampled = tf.keras.utils.to_categorical(train_labels_resampled, num_classes=NUM_CLASSES)
train_labels_int = np.argmax(train_labels, axis=1)
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels_int), y=train_labels_int)
class_weights = dict(enumerate(class_weights))
print(class_weights)

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))
for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(128, activation='relu')(x)
predictions = layers.Dense(NUM_CLASSES, activation='softmax')(x)
model = models.Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

model.summary()

model.fit(train_generator, epochs=NUM_EPOCHS, validation_data=(val_images, val_labels), class_weight=class_weights)
test_loss, test_accuracy = model.evaluate(test_images, test_labels)
print(f'Test accuracy: {test_accuracy}')
model.save('/content/drive/MyDrive/Main dataset/NewModelInshaAllahChalJayga.h5')

def load_and_preprocess_image(image_path):
    image = tf.keras.preprocessing.image.load_img(image_path,target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))
    image = tf.keras.preprocessing.image.img_to_array(image)
    image = np.expand_dims(image, axis=0)
    return image

saved_model = tf.keras.models.load_model('/content/drive/MyDrive/Main dataset/NewModelInshaAllahChalJayga.h5')

new_image_path = '/content/drive/MyDrive/Main dataset/car.jpeg'
new_image = load_and_preprocess_image(new_image_path)
prediction = saved_model.predict(new_image)
predicted_class = np.argmax(prediction)

label_encoder = LabelEncoder()
label_encoder.fit(['Aphids', 'Army worm', 'Bacterial Blight', 'Healthy','Powdery Mildew','Target spot', 'Unkown'])
predicted_class_name = label_encoder.inverse_transform([predicted_class])[0]

print(f'Predicted disease: {predicted_class_name}')